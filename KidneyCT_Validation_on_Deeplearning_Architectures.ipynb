{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCao6Q9dkYMDBuuMyHIiXf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaishak-krishnan/Kidney-CT-Project/blob/main/KidneyCT_Validation_on_Deeplearning_Architectures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow pandas scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVcw_f3vRQAN",
        "outputId": "22504370-a2e9-4b3f-9f5f-1ba1e0839b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\program files\\python311\\lib\\site-packages (2.17.0)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: pandas in c:\\program files\\python311\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in c:\\program files\\python311\\lib\\site-packages (1.5.1)\n",
            "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\program files\\python311\\lib\\site-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.2)\n",
            "Requirement already satisfied: setuptools in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (65.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.65.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\program files\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\program files\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\program files\\python311\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\program files\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\program files\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in c:\\program files\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\program files\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in c:\\program files\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\program files\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\program files\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\program files\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\program files\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\program files\\python311\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\program files\\python311\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\program files\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jb347ANWmGD",
        "outputId": "8bea3d13-2787-4061-deb1-3889ccb2391f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\program files\\python311\\lib\\site-packages (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\program files\\python311\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\program files\\python311\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\program files\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\program files\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhFKbzHNQ4HT",
        "outputId": "75947a55-3471-4c31-c351-796b5009e240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7467 validated image filenames belonging to 4 classes.\n",
            "Found 2489 validated image filenames belonging to 4 classes.\n",
            "Found 2490 validated image filenames belonging to 4 classes.\n",
            "Training samples: 7467\n",
            "Validation samples: 2489\n",
            "Test samples: 2490\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "kidney_data = pd.read_csv(\"E:/Workspace/Final Project/ct-kidney-dataset-normal-cyst-tumor-and-stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/kidneyData.csv\")\n",
        "\n",
        "# Define constants\n",
        "IMG_SIZE = (224, 224)  # Standard image size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Split the data into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(kidney_data, test_size=0.2, stratify=kidney_data['Class'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.25, stratify=train_data['Class'], random_state=42)  # 60% train, 20% val, 20% test\n",
        "\n",
        "# Initialize data augmentation and rescaling generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,                # Normalize pixel values to [0,1]\n",
        "    horizontal_flip=True,           # Randomly flip images horizontally\n",
        "    rotation_range=15,              # Rotate images by up to 15 degrees\n",
        "    zoom_range=0.1                  # Zoom in on images by up to 10%\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)  # Only rescale validation and test images\n",
        "\n",
        "# Create data generators for training, validation, and test sets\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_data,\n",
        "    x_col='path',                   # Path to images\n",
        "    y_col='Class',                  # Class labels\n",
        "    target_size=IMG_SIZE,           # Resize images to IMG_SIZE\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'        # Use categorical labels for multi-class classification\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_dataframe(\n",
        "    val_data,\n",
        "    x_col='path',\n",
        "    y_col='Class',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_dataframe(\n",
        "    test_data,\n",
        "    x_col='path',\n",
        "    y_col='Class',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Print summary of data\n",
        "print(f\"Training samples: {train_generator.samples}\")\n",
        "print(f\"Validation samples: {val_generator.samples}\")\n",
        "print(f\"Test samples: {test_generator.samples}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming kidney_data is the loaded dataset\n",
        "# Summary of dataset\n",
        "print(\"Dataset Overview\")\n",
        "print(\"----------------\")\n",
        "print(\"Total images:\", len(kidney_data))\n",
        "\n",
        "# Display class distribution\n",
        "class_distribution = kidney_data['Class'].value_counts()\n",
        "print(\"\\nClass Distribution:\")\n",
        "print(class_distribution)\n",
        "\n",
        "# Summary of preprocessing\n",
        "print(\"\\nData Preprocessing:\")\n",
        "print(\"1. Resized all images to 224x224.\")\n",
        "print(\"2. Applied data augmentation: horizontal flip, rotation (15 degrees), and zoom (10%).\")\n",
        "print(\"3. Normalized pixel values to [0, 1] range.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8SVVte5R38l",
        "outputId": "88b6b823-a423-45f8-d653-cc09fc39a7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Overview\n",
            "----------------\n",
            "Total images: 12446\n",
            "\n",
            "Class Distribution:\n",
            "Class\n",
            "Normal    5077\n",
            "Cyst      3709\n",
            "Tumor     2283\n",
            "Stone     1377\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Data Preprocessing:\n",
            "1. Resized all images to 224x224.\n",
            "2. Applied data augmentation: horizontal flip, rotation (15 degrees), and zoom (10%).\n",
            "3. Normalized pixel values to [0, 1] range.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n"
      ],
      "metadata": {
        "id": "osHd0zte2HSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming train_generator, val_generator, and test_generator are already defined\n",
        "# Define and compile VGG16 model\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "vgg16_base.trainable = False  # Freeze base layers\n",
        "\n",
        "def build_model(base_model):\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(len(train_generator.class_indices), activation='softmax')  # Number of classes in the output layer\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "vgg16_model = build_model(vgg16_base)\n",
        "\n",
        "# Train the model\n",
        "vgg16_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = vgg16_model.evaluate(test_generator, verbose=0)\n",
        "y_true = test_generator.classes\n",
        "y_pred = vgg16_model.predict(test_generator, verbose=0).argmax(axis=1)\n",
        "\n",
        "# Calculate classification metrics\n",
        "report = classification_report(y_true, y_pred, target_names=list(train_generator.class_indices.keys()), output_dict=True)\n",
        "metrics_df = pd.DataFrame(report).transpose()\n",
        "metrics_df['loss'] = test_loss  # Add test loss to the table\n",
        "\n",
        "# Display results\n",
        "print(f\"VGG16 Model Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"VGG16 Model Test Loss: {test_loss:.4f}\")\n",
        "print(metrics_df[['precision', 'recall', 'f1-score', 'support', 'loss']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjHG6vOkXPrX",
        "outputId": "a6db9eba-e2f8-4850-f64b-642981d0c6eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m931s\u001b[0m 4s/step - accuracy: 0.5637 - loss: 1.0917 - val_accuracy: 0.7348 - val_loss: 0.7452\n",
            "Epoch 2/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m985s\u001b[0m 4s/step - accuracy: 0.7384 - loss: 0.7298 - val_accuracy: 0.7670 - val_loss: 0.5809\n",
            "Epoch 3/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1008s\u001b[0m 4s/step - accuracy: 0.8043 - loss: 0.5534 - val_accuracy: 0.8108 - val_loss: 0.5297\n",
            "Epoch 4/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m989s\u001b[0m 4s/step - accuracy: 0.8305 - loss: 0.4771 - val_accuracy: 0.8501 - val_loss: 0.4278\n",
            "Epoch 5/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1004s\u001b[0m 4s/step - accuracy: 0.8613 - loss: 0.4023 - val_accuracy: 0.8634 - val_loss: 0.4076\n",
            "VGG16 Model Test Accuracy: 0.8687\n",
            "VGG16 Model Test Loss: 0.3970\n",
            "              precision    recall  f1-score      support      loss\n",
            "Cyst           0.285239  0.346361  0.312842   742.000000  0.397031\n",
            "Normal         0.402764  0.401575  0.402169  1016.000000  0.397031\n",
            "Stone          0.093750  0.087273  0.090395   275.000000  0.397031\n",
            "Tumor          0.209375  0.146608  0.172458   457.000000  0.397031\n",
            "accuracy       0.303614  0.303614  0.303614     0.303614  0.397031\n",
            "macro avg      0.247782  0.245454  0.244466  2490.000000  0.397031\n",
            "weighted avg   0.298121  0.303614  0.298958  2490.000000  0.397031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define and compile VGG19 model\n",
        "vgg19_base = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "vgg19_base.trainable = False  # Freeze base layers\n",
        "\n",
        "def build_model(base_model):\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(len(train_generator.class_indices), activation='softmax')  # Use number of classes in output layer\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "vgg19_model = build_model(vgg19_base)\n",
        "\n",
        "# Train the model\n",
        "vgg19_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate and calculate metrics\n",
        "test_loss, test_accuracy = vgg19_model.evaluate(test_generator, verbose=0)\n",
        "y_true = test_generator.classes\n",
        "y_pred = vgg19_model.predict(test_generator, verbose=0).argmax(axis=1)\n",
        "\n",
        "# Classification report for metrics\n",
        "report = classification_report(y_true, y_pred, target_names=list(train_generator.class_indices.keys()), output_dict=True)\n",
        "metrics_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Display results\n",
        "print(f\"VGG19 Model Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(metrics_df[['precision', 'recall', 'f1-score']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6mjABTIYMOJ",
        "outputId": "599d77aa-2ef1-4803-e543-a5454fb6445f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1106s\u001b[0m 5s/step - accuracy: 0.5200 - loss: 1.1721 - val_accuracy: 0.6826 - val_loss: 0.8779\n",
            "Epoch 2/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1066s\u001b[0m 5s/step - accuracy: 0.6975 - loss: 0.8319 - val_accuracy: 0.7131 - val_loss: 0.7503\n",
            "Epoch 3/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1051s\u001b[0m 4s/step - accuracy: 0.7442 - loss: 0.6875 - val_accuracy: 0.7730 - val_loss: 0.6052\n",
            "Epoch 4/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1053s\u001b[0m 4s/step - accuracy: 0.7822 - loss: 0.5918 - val_accuracy: 0.7971 - val_loss: 0.5317\n",
            "Epoch 5/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1057s\u001b[0m 5s/step - accuracy: 0.8121 - loss: 0.5185 - val_accuracy: 0.7991 - val_loss: 0.5246\n",
            "VGG19 Model Test Accuracy: 0.8004\n",
            "              precision    recall  f1-score\n",
            "Cyst           0.305785  0.299191  0.302452\n",
            "Normal         0.415902  0.535433  0.468158\n",
            "Stone          0.123457  0.036364  0.056180\n",
            "Tumor          0.178667  0.146608  0.161058\n",
            "accuracy       0.338554  0.338554  0.338554\n",
            "macro avg      0.255953  0.254399  0.246962\n",
            "weighted avg   0.307249  0.338554  0.316916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Define and compile ResNet50 model\n",
        "resnet50_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "resnet50_base.trainable = False  # Freeze base layers\n",
        "\n",
        "resnet50_model = build_model(resnet50_base)\n",
        "\n",
        "# Train the model\n",
        "resnet50_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate and calculate metrics\n",
        "test_loss, test_accuracy = resnet50_model.evaluate(test_generator, verbose=0)\n",
        "y_true = test_generator.classes\n",
        "y_pred = resnet50_model.predict(test_generator, verbose=0).argmax(axis=1)\n",
        "\n",
        "# Classification report for metrics\n",
        "report = classification_report(y_true, y_pred, target_names=list(train_generator.class_indices.keys()), output_dict=True)\n",
        "metrics_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Display results\n",
        "print(f\"ResNet50 Model Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(metrics_df[['precision', 'recall', 'f1-score']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URPh_NGnYOEr",
        "outputId": "f56ea1c8-554e-4af8-a6cb-6aec1fa36331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 2s/step - accuracy: 0.4493 - loss: 1.2589 - val_accuracy: 0.6123 - val_loss: 0.9907\n",
            "Epoch 2/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 2s/step - accuracy: 0.6032 - loss: 0.9945 - val_accuracy: 0.6714 - val_loss: 0.8678\n",
            "Epoch 3/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 2s/step - accuracy: 0.6343 - loss: 0.9112 - val_accuracy: 0.6304 - val_loss: 0.8951\n",
            "Epoch 4/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 2s/step - accuracy: 0.6433 - loss: 0.8751 - val_accuracy: 0.5745 - val_loss: 1.0074\n",
            "Epoch 5/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 2s/step - accuracy: 0.6667 - loss: 0.8000 - val_accuracy: 0.7107 - val_loss: 0.7688\n",
            "ResNet50 Model Test Accuracy: 0.7129\n",
            "              precision    recall  f1-score\n",
            "Cyst           0.289805  0.340970  0.313313\n",
            "Normal         0.398671  0.472441  0.432432\n",
            "Stone          0.000000  0.000000  0.000000\n",
            "Tumor          0.188725  0.168490  0.178035\n",
            "accuracy       0.325301  0.325301  0.325301\n",
            "macro avg      0.219300  0.245475  0.230945\n",
            "weighted avg   0.283668  0.325301  0.302486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "# Define and compile EfficientNetB0 model\n",
        "efficientnetb0_base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "efficientnetb0_base.trainable = False  # Freeze base layers\n",
        "\n",
        "efficientnetb0_model = build_model(efficientnetb0_base)\n",
        "\n",
        "# Train the model\n",
        "efficientnetb0_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate and calculate metrics\n",
        "test_loss, test_accuracy = efficientnetb0_model.evaluate(test_generator, verbose=0)\n",
        "y_true = test_generator.classes\n",
        "y_pred = efficientnetb0_model.predict(test_generator, verbose=0).argmax(axis=1)\n",
        "\n",
        "# Classification report for metrics\n",
        "report = classification_report(y_true, y_pred, target_names=list(train_generator.class_indices.keys()), output_dict=True)\n",
        "metrics_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Display results\n",
        "print(f\"EfficientNetB0 Model Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(metrics_df[['precision', 'recall', 'f1-score']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQe1J8VxYTvc",
        "outputId": "b7920ecd-e1ff-4908-9f4b-010c685e63ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 986ms/step - accuracy: 0.4073 - loss: 1.2918 - val_accuracy: 0.4078 - val_loss: 1.2958\n",
            "Epoch 2/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 975ms/step - accuracy: 0.4075 - loss: 1.2851 - val_accuracy: 0.4078 - val_loss: 1.2877\n",
            "Epoch 3/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 980ms/step - accuracy: 0.4039 - loss: 1.2812 - val_accuracy: 0.4078 - val_loss: 1.2840\n",
            "Epoch 4/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 972ms/step - accuracy: 0.4028 - loss: 1.2864 - val_accuracy: 0.4078 - val_loss: 1.2822\n",
            "Epoch 5/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 973ms/step - accuracy: 0.4100 - loss: 1.2792 - val_accuracy: 0.4078 - val_loss: 1.2833\n",
            "EfficientNetB0 Model Test Accuracy: 0.4080\n",
            "              precision    recall  f1-score\n",
            "Cyst           0.000000  0.000000  0.000000\n",
            "Normal         0.408032  1.000000  0.579578\n",
            "Stone          0.000000  0.000000  0.000000\n",
            "Tumor          0.000000  0.000000  0.000000\n",
            "accuracy       0.408032  0.408032  0.408032\n",
            "macro avg      0.102008  0.250000  0.144894\n",
            "weighted avg   0.166490  0.408032  0.236486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "\n",
        "# Define and compile DenseNet121 model\n",
        "densenet121_base = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "densenet121_base.trainable = False  # Freeze base layers\n",
        "\n",
        "densenet121_model = build_model(densenet121_base)\n",
        "\n",
        "# Train the model\n",
        "densenet121_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate and calculate metrics\n",
        "test_loss, test_accuracy = densenet121_model.evaluate(test_generator, verbose=0)\n",
        "y_true = test_generator.classes\n",
        "y_pred = densenet121_model.predict(test_generator, verbose=0).argmax(axis=1)\n",
        "\n",
        "# Classification report for metrics\n",
        "report = classification_report(y_true, y_pred, target_names=list(train_generator.class_indices.keys()), output_dict=True)\n",
        "metrics_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Display results\n",
        "print(f\"DenseNet121 Model Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(metrics_df[['precision', 'recall', 'f1-score']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjFnuj5UYSQd",
        "outputId": "6161edf2-531e-405e-f56f-b0c78e606b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 2s/step - accuracy: 0.6645 - loss: 0.8578 - val_accuracy: 0.7879 - val_loss: 0.5479\n",
            "Epoch 2/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 2s/step - accuracy: 0.8665 - loss: 0.3729 - val_accuracy: 0.8662 - val_loss: 0.3635\n",
            "Epoch 3/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 2s/step - accuracy: 0.9107 - loss: 0.2622 - val_accuracy: 0.9072 - val_loss: 0.2587\n",
            "Epoch 4/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 2s/step - accuracy: 0.9276 - loss: 0.2162 - val_accuracy: 0.8803 - val_loss: 0.3262\n",
            "Epoch 5/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 2s/step - accuracy: 0.9339 - loss: 0.1956 - val_accuracy: 0.8971 - val_loss: 0.2570\n",
            "DenseNet121 Model Test Accuracy: 0.9068\n",
            "              precision    recall  f1-score\n",
            "Cyst           0.301513  0.349057  0.323548\n",
            "Normal         0.412221  0.418307  0.415242\n",
            "Stone          0.096899  0.090909  0.093809\n",
            "Tumor          0.190058  0.142232  0.162703\n",
            "accuracy       0.310843  0.310843  0.310843\n",
            "macro avg      0.250173  0.250126  0.248825\n",
            "weighted avg   0.303632  0.310843  0.306069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet169\n",
        "\n",
        "# Define and compile DenseNet-169 model\n",
        "densenet169_base = DenseNet169(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "densenet169_base.trainable = False\n",
        "\n",
        "densenet169_model = build_model(densenet169_base)\n",
        "\n",
        "# Train the model\n",
        "densenet169_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = densenet169_model.evaluate(test_generator, verbose=0)\n",
        "y_true = test_generator.classes\n",
        "y_pred = densenet169_model.predict(test_generator, verbose=0).argmax(axis=1)\n",
        "\n",
        "# Classification metrics\n",
        "report = classification_report(y_true, y_pred, target_names=list(train_generator.class_indices.keys()), output_dict=True)\n",
        "metrics_df = pd.DataFrame(report).transpose()\n",
        "metrics_df['loss'] = test_loss\n",
        "\n",
        "# Display results\n",
        "print(f\"DenseNet-169 Model Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(metrics_df[['precision', 'recall', 'f1-score', 'support', 'loss']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsjAP2mXyPNA",
        "outputId": "37fd9e34-4451-460e-aa92-e289a94562df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m51877672/51877672\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 3s/step - accuracy: 0.6578 - loss: 0.8826 - val_accuracy: 0.8421 - val_loss: 0.3980\n",
            "Epoch 2/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 3s/step - accuracy: 0.9012 - loss: 0.2929 - val_accuracy: 0.9024 - val_loss: 0.2744\n",
            "Epoch 3/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 2s/step - accuracy: 0.9376 - loss: 0.1942 - val_accuracy: 0.9321 - val_loss: 0.1896\n",
            "Epoch 4/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 2s/step - accuracy: 0.9417 - loss: 0.1766 - val_accuracy: 0.9345 - val_loss: 0.1706\n",
            "Epoch 5/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 2s/step - accuracy: 0.9578 - loss: 0.1307 - val_accuracy: 0.9385 - val_loss: 0.1634\n",
            "DenseNet-169 Model Test Accuracy: 0.9450\n",
            "              precision    recall  f1-score      support      loss\n",
            "Cyst           0.280959  0.284367  0.282652   742.000000  0.142323\n",
            "Normal         0.403458  0.413386  0.408362  1016.000000  0.142323\n",
            "Stone          0.120130  0.134545  0.126930   275.000000  0.142323\n",
            "Tumor          0.200000  0.170678  0.184179   457.000000  0.142323\n",
            "accuracy       0.299598  0.299598  0.299598     0.299598  0.142323\n",
            "macro avg      0.251137  0.250744  0.250531  2490.000000  0.142323\n",
            "weighted avg   0.298322  0.299598  0.298674  2490.000000  0.142323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet201\n",
        "\n",
        "# Define and compile DenseNet-201 model\n",
        "densenet201_base = DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "densenet201_base.trainable = False\n",
        "\n",
        "densenet201_model = build_model(densenet201_base)\n",
        "\n",
        "# Train the model\n",
        "densenet201_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = densenet201_model.evaluate(test_generator, verbose=0)\n",
        "y_true = test_generator.classes\n",
        "y_pred = densenet201_model.predict(test_generator, verbose=0).argmax(axis=1)\n",
        "\n",
        "# Classification metrics\n",
        "report = classification_report(y_true, y_pred, target_names=list(train_generator.class_indices.keys()), output_dict=True)\n",
        "metrics_df = pd.DataFrame(report).transpose()\n",
        "metrics_df['loss'] = test_loss\n",
        "\n",
        "# Display results\n",
        "print(f\"DenseNet-201 Model Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(metrics_df[['precision', 'recall', 'f1-score', 'support', 'loss']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZsPinQ-yRxA",
        "outputId": "e27b140d-b1cc-4579-ff6a-f239122b8862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m74836368/74836368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m888s\u001b[0m 4s/step - accuracy: 0.6636 - loss: 0.8901 - val_accuracy: 0.8763 - val_loss: 0.3654\n",
            "Epoch 2/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m848s\u001b[0m 4s/step - accuracy: 0.8933 - loss: 0.3083 - val_accuracy: 0.9056 - val_loss: 0.2533\n",
            "Epoch 3/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m751s\u001b[0m 3s/step - accuracy: 0.9335 - loss: 0.2083 - val_accuracy: 0.9253 - val_loss: 0.2059\n",
            "Epoch 4/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m746s\u001b[0m 3s/step - accuracy: 0.9505 - loss: 0.1550 - val_accuracy: 0.9425 - val_loss: 0.1580\n",
            "Epoch 5/5\n",
            "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m756s\u001b[0m 3s/step - accuracy: 0.9537 - loss: 0.1300 - val_accuracy: 0.9494 - val_loss: 0.1363\n",
            "DenseNet-201 Model Test Accuracy: 0.9606\n",
            "              precision    recall  f1-score      support      loss\n",
            "Cyst           0.312343  0.334232  0.322917   742.000000  0.116252\n",
            "Normal         0.411647  0.403543  0.407555  1016.000000  0.116252\n",
            "Stone          0.110672  0.101818  0.106061   275.000000  0.116252\n",
            "Tumor          0.194631  0.190372  0.192478   457.000000  0.116252\n",
            "accuracy       0.310442  0.310442  0.310442     0.310442  0.116252\n",
            "macro avg      0.257323  0.257491  0.257252  2490.000000  0.116252\n",
            "weighted avg   0.308985  0.310442  0.309562  2490.000000  0.116252\n"
          ]
        }
      ]
    }
  ]
}